{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paragraphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_mining = \"\"\"Data mining is the process of discovering patterns, \n",
    "trends, and relationships in large datasets by analyzing data from multiple perspectives. \n",
    "It uses techniques from statistics, machine learning, and database systems to extract valuable \n",
    "insights that can inform decision-making. Often used in fields such as marketing, healthcare, \n",
    "and finance, data mining identifies anomalies, clusters, and associations that might otherwise go unnoticed. \n",
    "Tools like decision trees, clustering algorithms, and association rule mining enable businesses to improve strategies,\n",
    " such as predicting customer behavior or detecting fraud.\"\"\"\n",
    "\n",
    "machine_learning = \"\"\"Machine learning is a subset of artificial intelligence that allows systems to \n",
    "learn and improve from experience without being explicitly programmed. By utilizing algorithms that process \n",
    "and analyze data, machine learning models can perform tasks like classification, regression, and clustering. \n",
    "Applications range from personalized recommendations on streaming platforms to real-time language translation. \n",
    "The key to successful machine learning lies in providing high-quality data and selecting appropriate algorithms, \n",
    "such as neural networks for deep learning or support vector machines for classification tasks.\"\"\"\n",
    "\n",
    "meta_heuristics = \"\"\"Metaheuristics are high-level strategies designed to solve complex optimization \n",
    "problems that are difficult to address with traditional methods. These techniques, such as genetic algorithms, \n",
    "simulated annealing, and particle swarm optimization, provide approximate solutions by exploring the search \n",
    "space efficiently. Metaheuristics are particularly useful for problems in logistics, engineering design, \n",
    "and scheduling, where the objective is to maximize or minimize certain criteria. Their ability to avoid local \n",
    "optima and handle large problem sizes makes them indispensable in fields requiring innovative problem-solving approaches.\"\"\"\n",
    "\n",
    "vision = \"\"\"In the context of artificial intelligence, vision refers to the capability of machines to \n",
    "interpret and understand visual data from the world. Computer vision, a prominent area of study, enables systems \n",
    "to analyze images and videos to perform tasks like object detection, facial recognition, and image segmentation. \n",
    "Using deep learning models, such as convolutional neural networks (CNNs), vision systems are applied in industries \n",
    "like healthcare for medical imaging, autonomous vehicles for navigation, and retail for inventory management. \n",
    "Advances in vision continue to push the boundaries of machine perception, making systems increasingly adept \n",
    "at mimicking human sight.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 0, 'analyze': 1, 'anomaly': 2, 'association': 3, 'behavior': 4, 'business': 5, 'cluster': 6, 'clustering': 7, 'customer': 8, 'data': 9, 'database': 10, 'dataset': 11, 'datum': 12, 'decision': 13, 'detect': 14, 'discover': 15, 'enable': 16, 'extract': 17, 'field': 18, 'finance': 19, 'fraud': 20, 'healthcare': 21, 'identifie': 22, 'improve': 23, 'inform': 24, 'insight': 25, 'large': 26, 'learning': 27, 'like': 28, 'machine': 29, 'making': 30, 'marketing': 31, 'mining': 32, 'multiple': 33, 'pattern': 34, 'perspective': 35, 'predict': 36, 'process': 37, 'relationship': 38, 'rule': 39, 'statistic': 40, 'strategy': 41, 'system': 42, 'technique': 43, 'tool': 44, 'tree': 45, 'trend': 46, 'unnoticed': 47, 'use': 48, 'valuable': 49, 'allow': 50, 'application': 51, 'appropriate': 52, 'artificial': 53, 'classification': 54, 'deep': 55, 'experience': 56, 'explicitly': 57, 'high': 58, 'intelligence': 59, 'key': 60, 'language': 61, 'learn': 62, 'lie': 63, 'model': 64, 'network': 65, 'neural': 66, 'perform': 67, 'personalized': 68, 'platform': 69, 'program': 70, 'provide': 71, 'quality': 72, 'range': 73, 'real': 74, 'recommendation': 75, 'regression': 76, 'select': 77, 'stream': 78, 'subset': 79, 'successful': 80, 'support': 81, 'task': 82, 'time': 83, 'translation': 84, 'utilize': 85, 'vector': 86, 'ability': 87, 'address': 88, 'annealing': 89, 'approach': 90, 'approximate': 91, 'avoid': 92, 'certain': 93, 'complex': 94, 'criterion': 95, 'design': 96, 'difficult': 97, 'efficiently': 98, 'engineering': 99, 'explore': 100, 'genetic': 101, 'handle': 102, 'indispensable': 103, 'innovative': 104, 'level': 105, 'local': 106, 'logistic': 107, 'make': 108, 'maximize': 109, 'metaheuristic': 110, 'method': 111, 'minimize': 112, 'objective': 113, 'optima': 114, 'optimization': 115, 'particle': 116, 'particularly': 117, 'problem': 118, 'require': 119, 'scheduling': 120, 'search': 121, 'simulate': 122, 'size': 123, 'solution': 124, 'solve': 125, 'space': 126, 'swarm': 127, 'traditional': 128, 'useful': 129, 'adept': 130, 'advance': 131, 'apply': 132, 'area': 133, 'autonomous': 134, 'boundary': 135, 'capability': 136, 'cnns': 137, 'computer': 138, 'context': 139, 'continue': 140, 'convolutional': 141, 'detection': 142, 'facial': 143, 'human': 144, 'image': 145, 'imaging': 146, 'increasingly': 147, 'industry': 148, 'interpret': 149, 'inventory': 150, 'management': 151, 'medical': 152, 'mimic': 153, 'navigation': 154, 'object': 155, 'perception': 156, 'prominent': 157, 'push': 158, 'recognition': 159, 'refer': 160, 'retail': 161, 'segmentation': 162, 'sight': 163, 'study': 164, 'understand': 165, 'vehicle': 166, 'video': 167, 'vision': 168, 'visual': 169, 'world': 170}\n"
     ]
    }
   ],
   "source": [
    "paragraphs = [data_mining, machine_learning, meta_heuristics, vision]\n",
    "texts = []\n",
    "for p in paragraphs:\n",
    "    text = []\n",
    "    doc = nlp(p.lower().replace(\"\\n\", \" \"))\n",
    "    for w in doc:\n",
    "        if not w.is_stop and not w.is_punct and not w.like_num and len(w.text) > 2:\n",
    "            text.append(w.lemma_)\n",
    "    texts.append(text)\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "print(dictionary.token2id)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Dirichlet allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: asymmetric, Best Eta: 0.01, Coherence Score: 0.9001317374368984\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LdaModel\n",
    "import numpy as np\n",
    "\n",
    "alpha_values = list(np.arange(0.01, 1.01, 0.3)) + ['symmetric', 'asymmetric']\n",
    "eta_values = list(np.arange(0.01, 1.01, 0.3)) + ['symmetric']\n",
    "coherence_scores = []\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    for eta in eta_values:\n",
    "        ldamodel = LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=4,\n",
    "            random_state=42,\n",
    "            alpha=alpha,\n",
    "            eta=eta,\n",
    "            passes=10\n",
    "        )\n",
    "        coherence_model_lda = CoherenceModel(\n",
    "            model=ldamodel,\n",
    "            texts=texts,\n",
    "            dictionary=dictionary,\n",
    "            coherence='c_v'\n",
    "        )\n",
    "        coherence_score = coherence_model_lda.get_coherence()\n",
    "        coherence_scores.append((alpha, eta, coherence_score))\n",
    "\n",
    "\n",
    "best_params = max(coherence_scores, key=lambda x: x[2])\n",
    "print(f\"Best Alpha: {best_params[0]}, Best Eta: {best_params[1]}, Coherence Score: {best_params[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.031*\"problem\" + 0.020*\"system\" + 0.019*\"machine\" + 0.018*\"vision\" + 0.015*\"learning\" + 0.015*\"like\" + 0.014*\"solve\" + 0.014*\"metaheuristic\" + 0.013*\"algorithm\" + 0.013*\"design\"'),\n",
       " (1,\n",
       "  '0.044*\"machine\" + 0.040*\"learning\" + 0.025*\"task\" + 0.024*\"datum\" + 0.023*\"system\" + 0.020*\"algorithm\" + 0.020*\"classification\" + 0.018*\"like\" + 0.017*\"model\" + 0.015*\"vision\"'),\n",
       " (2,\n",
       "  '0.028*\"machine\" + 0.027*\"datum\" + 0.023*\"learning\" + 0.022*\"mining\" + 0.020*\"system\" + 0.018*\"like\" + 0.017*\"algorithm\" + 0.017*\"vision\" + 0.016*\"analyze\" + 0.015*\"association\"')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "---------------------------------\n",
    "num_topics=3: three main topics and machine learning overlap with all of them \n",
    "---------------------------------\n",
    "'''\n",
    "\n",
    "ldamodel = LdaModel(corpus=corpus, num_topics=3, id2word=dictionary, eta=0.01,alpha='asymmetric')\n",
    "ldamodel.show_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.042*\"problem\" + 0.025*\"solve\" + 0.021*\"optimization\" + 0.020*\"metaheuristic\" + 0.018*\"design\" + 0.016*\"machine\" + 0.015*\"make\" + 0.014*\"algorithm\" + 0.014*\"local\" + 0.014*\"high\"'),\n",
       " (1,\n",
       "  '0.025*\"datum\" + 0.023*\"algorithm\" + 0.023*\"mining\" + 0.023*\"problem\" + 0.022*\"machine\" + 0.021*\"learning\" + 0.017*\"association\" + 0.017*\"decision\" + 0.016*\"large\" + 0.015*\"technique\"'),\n",
       " (2,\n",
       "  '0.055*\"vision\" + 0.040*\"system\" + 0.026*\"image\" + 0.026*\"like\" + 0.026*\"machine\" + 0.016*\"learning\" + 0.015*\"analyze\" + 0.015*\"datum\" + 0.015*\"enable\" + 0.014*\"healthcare\"'),\n",
       " (3,\n",
       "  '0.052*\"machine\" + 0.049*\"learning\" + 0.029*\"datum\" + 0.025*\"like\" + 0.024*\"algorithm\" + 0.020*\"task\" + 0.019*\"classification\" + 0.019*\"system\" + 0.016*\"analyze\" + 0.015*\"mining\"')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "---------------------------------\n",
    "num_topics=4:Topics overlap significantly, especially between topics 2 and 3.\n",
    "The results lack strong separation between the four distinct input concepts.\n",
    "---------------------------------\n",
    "'''\n",
    "\n",
    "ldamodel = LdaModel(corpus=corpus, num_topics=4, id2word=dictionary,eta=0.01,alpha='asymmetric')\n",
    "ldamodel.show_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.040*\"learning\" + 0.038*\"machine\" + 0.028*\"datum\" + 0.022*\"system\" + 0.020*\"vision\" + 0.019*\"like\" + 0.018*\"task\" + 0.017*\"algorithm\" + 0.017*\"analyze\" + 0.013*\"neural\"'),\n",
       " (1,\n",
       "  '0.032*\"vision\" + 0.030*\"system\" + 0.024*\"like\" + 0.020*\"image\" + 0.020*\"machine\" + 0.016*\"mining\" + 0.014*\"make\" + 0.014*\"learning\" + 0.014*\"analyze\" + 0.012*\"datum\"'),\n",
       " (2,\n",
       "  '0.043*\"problem\" + 0.024*\"solve\" + 0.022*\"optimization\" + 0.019*\"design\" + 0.018*\"metaheuristic\" + 0.018*\"system\" + 0.015*\"algorithm\" + 0.014*\"make\" + 0.014*\"vision\" + 0.013*\"minimize\"'),\n",
       " (3,\n",
       "  '0.031*\"mining\" + 0.030*\"datum\" + 0.028*\"machine\" + 0.026*\"system\" + 0.026*\"like\" + 0.020*\"association\" + 0.019*\"enable\" + 0.018*\"decision\" + 0.018*\"healthcare\" + 0.016*\"analyze\"'),\n",
       " (4,\n",
       "  '0.075*\"machine\" + 0.059*\"learning\" + 0.040*\"classification\" + 0.039*\"algorithm\" + 0.034*\"task\" + 0.030*\"datum\" + 0.022*\"application\" + 0.021*\"stream\" + 0.021*\"utilize\" + 0.020*\"system\"'),\n",
       " (5,\n",
       "  '0.071*\"problem\" + 0.041*\"metaheuristic\" + 0.037*\"design\" + 0.030*\"optimization\" + 0.023*\"solve\" + 0.021*\"approximate\" + 0.020*\"local\" + 0.020*\"innovative\" + 0.020*\"large\" + 0.020*\"level\"')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "---------------------------------\n",
    "num_topics=6: Topics still overlap\n",
    "Topic 1 and Topic 3 focus on problem-solving and optimization, heavily associated with metaheuristics.\n",
    "Topic 0 and Topic 4 include terms from both data mining and machine learning, showing blurred boundaries.\n",
    "Topic 5 highlights machine learning concepts but overlaps with vision-related terms.\n",
    "------------------------------------\n",
    "\n",
    "'''\n",
    "\n",
    "ldamodel = LdaModel(corpus=corpus, num_topics=6, id2word=dictionary, eta=0.01,alpha='asymmetric')\n",
    "ldamodel.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent semantic indexing (LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'num_topics': 3, 'chunksize': 200, 'decay': 0.5, 'power_iters': 2}\n",
      "Best Coherence Score: 0.9462417049114343\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LsiModel\n",
    "from gensim.models import CoherenceModel\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "num_topics_values = [3, 5, 10, 15]\n",
    "chunksize_values = [200, 500, 1000]\n",
    "decay_values = [0.5, 0.75, 1.0]\n",
    "power_iters_values = [2, 5, 10]\n",
    "\n",
    "best_coherence = -1\n",
    "best_params = {}\n",
    "\n",
    "\n",
    "for num_topics in num_topics_values:\n",
    "    for chunksize in chunksize_values:\n",
    "        for decay in decay_values:\n",
    "            for power_iters in power_iters_values:\n",
    "                lsi_model = LsiModel(\n",
    "                    corpus=corpus,\n",
    "                    num_topics=num_topics,\n",
    "                    id2word=dictionary,\n",
    "                    chunksize=chunksize,\n",
    "                    decay=decay,\n",
    "                    power_iters=power_iters\n",
    "                )\n",
    "\n",
    "                \n",
    "                coherence_model = CoherenceModel(\n",
    "                    model=lsi_model,\n",
    "                    texts=texts,  \n",
    "                    dictionary=dictionary,\n",
    "                    coherence='c_v'\n",
    "                )\n",
    "                coherence_score = coherence_model.get_coherence()\n",
    "\n",
    "                \n",
    "                if coherence_score > best_coherence:\n",
    "                    best_coherence = coherence_score\n",
    "                    best_params = {\n",
    "                        'num_topics': num_topics,\n",
    "                        'chunksize': chunksize,\n",
    "                        'decay': decay,\n",
    "                        'power_iters': power_iters\n",
    "                    }\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Coherence Score:\", best_coherence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '-0.382*\"machine\" + -0.326*\"learning\" + -0.261*\"system\" + -0.239*\"datum\" + -0.226*\"vision\" + -0.204*\"like\" + -0.175*\"task\" + -0.160*\"algorithm\" + -0.148*\"analyze\" + -0.119*\"classification\"'),\n",
       " (1,\n",
       "  '-0.435*\"problem\" + -0.218*\"design\" + -0.218*\"solve\" + -0.218*\"optimization\" + -0.218*\"metaheuristic\" + -0.127*\"field\" + -0.127*\"strategy\" + -0.127*\"large\" + -0.127*\"technique\" + -0.126*\"algorithm\"'),\n",
       " (2,\n",
       "  '0.350*\"vision\" + -0.197*\"mining\" + -0.189*\"learning\" + 0.175*\"image\" + -0.149*\"datum\" + 0.144*\"system\" + -0.138*\"algorithm\" + -0.131*\"association\" + -0.131*\"decision\" + 0.131*\"problem\"')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lsimodel = LsiModel(corpus=corpus, num_topics=3, id2word=dictionary, chunksize=200,decay=0.5,power_iters=2)\n",
    "lsimodel.show_topics() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '-0.382*\"machine\" + -0.326*\"learning\" + -0.261*\"system\" + -0.239*\"datum\" + -0.226*\"vision\" + -0.204*\"like\" + -0.175*\"task\" + -0.160*\"algorithm\" + -0.148*\"analyze\" + -0.119*\"classification\"'),\n",
       " (1,\n",
       "  '0.435*\"problem\" + 0.218*\"design\" + 0.218*\"metaheuristic\" + 0.218*\"optimization\" + 0.218*\"solve\" + 0.127*\"large\" + 0.127*\"technique\" + 0.127*\"strategy\" + 0.127*\"field\" + 0.126*\"algorithm\"'),\n",
       " (2,\n",
       "  '0.350*\"vision\" + -0.197*\"mining\" + -0.189*\"learning\" + 0.175*\"image\" + -0.149*\"datum\" + 0.144*\"system\" + -0.138*\"algorithm\" + -0.131*\"decision\" + -0.131*\"association\" + 0.131*\"problem\"'),\n",
       " (3,\n",
       "  '0.308*\"mining\" + 0.205*\"decision\" + 0.205*\"association\" + -0.200*\"learning\" + -0.169*\"machine\" + -0.166*\"classification\" + -0.136*\"task\" + 0.133*\"enable\" + 0.133*\"healthcare\" + 0.121*\"vision\"')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsimodel = LsiModel(corpus=corpus, num_topics=4, id2word=dictionary, chunksize=200,decay=0.5,power_iters=2)\n",
    "lsimodel.show_topics() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.382*\"machine\" + 0.326*\"learning\" + 0.261*\"system\" + 0.239*\"datum\" + 0.226*\"vision\" + 0.204*\"like\" + 0.175*\"task\" + 0.160*\"algorithm\" + 0.148*\"analyze\" + 0.119*\"classification\"'),\n",
       " (1,\n",
       "  '0.435*\"problem\" + 0.218*\"design\" + 0.218*\"metaheuristic\" + 0.218*\"solve\" + 0.218*\"optimization\" + 0.127*\"large\" + 0.127*\"technique\" + 0.127*\"field\" + 0.127*\"strategy\" + 0.126*\"algorithm\"'),\n",
       " (2,\n",
       "  '0.350*\"vision\" + -0.197*\"mining\" + -0.189*\"learning\" + 0.175*\"image\" + -0.149*\"datum\" + 0.144*\"system\" + -0.138*\"algorithm\" + -0.131*\"decision\" + -0.131*\"association\" + 0.131*\"problem\"'),\n",
       " (3,\n",
       "  '0.308*\"mining\" + 0.205*\"decision\" + 0.205*\"association\" + -0.200*\"learning\" + -0.169*\"machine\" + -0.166*\"classification\" + -0.136*\"task\" + 0.133*\"healthcare\" + 0.133*\"enable\" + 0.121*\"vision\"')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "the model gave only 4 topics might be due to :\n",
    "Lack of Distinct Topics\n",
    "Sparse or Limited Data\n",
    "Overlap in Topics\n",
    "Not enough variability in the document-term matrix.\n",
    "'''\n",
    "\n",
    "lsimodel = LsiModel(corpus=corpus, num_topics=6, id2word=dictionary, chunksize=200,decay=0.5,power_iters=2)\n",
    "lsimodel.show_topics() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical Dirichlet process (HDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.023*enable + 0.020*analyze + 0.019*prominent + 0.018*lie + 0.018*technique + 0.017*minimize + 0.017*decision + 0.017*world + 0.016*facial + 0.015*pattern + 0.014*healthcare + 0.014*datum + 0.014*mining + 0.014*sight + 0.013*recommendation + 0.013*fraud + 0.013*difficult + 0.013*increasingly + 0.013*apply + 0.012*human'),\n",
       " (1,\n",
       "  '0.025*computer + 0.024*like + 0.020*decision + 0.020*system + 0.020*facial + 0.019*vision + 0.018*multiple + 0.016*model + 0.016*minimize + 0.016*subset + 0.015*continue + 0.015*task + 0.014*study + 0.013*size + 0.013*vehicle + 0.013*indispensable + 0.013*visual + 0.012*autonomous + 0.012*refer + 0.012*detect'),\n",
       " (2,\n",
       "  '0.026*platform + 0.025*learning + 0.021*machine + 0.019*algorithm + 0.019*classification + 0.017*cluster + 0.017*tree + 0.016*system + 0.015*local + 0.015*lie + 0.014*objective + 0.014*artificial + 0.013*successful + 0.013*behavior + 0.013*appropriate + 0.012*vision + 0.012*improve + 0.012*regression + 0.012*making + 0.012*explicitly'),\n",
       " (3,\n",
       "  '0.030*handle + 0.025*technique + 0.024*problem + 0.023*classification + 0.022*enable + 0.021*approximate + 0.019*complex + 0.018*high + 0.017*large + 0.017*metaheuristic + 0.016*design + 0.015*size + 0.015*annealing + 0.015*provide + 0.014*optimization + 0.014*require + 0.013*strategy + 0.013*difficult + 0.012*algorithm + 0.012*prominent'),\n",
       " (4,\n",
       "  '0.035*application + 0.034*behavior + 0.024*multiple + 0.022*handle + 0.020*lie + 0.020*vehicle + 0.019*difficult + 0.019*large + 0.018*real + 0.017*facial + 0.017*world + 0.017*adept + 0.016*finance + 0.016*industry + 0.016*cnns + 0.014*management + 0.014*strategy + 0.014*stream + 0.013*search + 0.013*refer'),\n",
       " (5,\n",
       "  '0.031*insight + 0.026*vehicle + 0.026*technique + 0.025*field + 0.024*genetic + 0.023*tree + 0.021*high + 0.020*decision + 0.018*select + 0.017*large + 0.017*metaheuristic + 0.017*require + 0.016*identifie + 0.016*task + 0.016*adept + 0.015*search + 0.014*appropriate + 0.013*time + 0.013*model + 0.012*particle'),\n",
       " (6,\n",
       "  '0.024*data + 0.023*task + 0.023*sight + 0.022*swarm + 0.021*detect + 0.020*select + 0.019*application + 0.017*local + 0.017*neural + 0.017*dataset + 0.017*quality + 0.014*unnoticed + 0.014*learning + 0.014*annealing + 0.014*require + 0.014*machine + 0.014*lie + 0.013*mimic + 0.013*solve + 0.012*metaheuristic'),\n",
       " (7,\n",
       "  '0.026*scheduling + 0.026*application + 0.023*high + 0.022*optima + 0.018*world + 0.018*recognition + 0.018*method + 0.017*relationship + 0.017*address + 0.017*personalized + 0.016*swarm + 0.016*use + 0.016*inform + 0.015*design + 0.014*retail + 0.014*decision + 0.014*deep + 0.014*particularly + 0.014*neural + 0.013*autonomous'),\n",
       " (8,\n",
       "  '0.029*address + 0.025*objective + 0.023*explore + 0.021*tree + 0.021*difficult + 0.019*program + 0.018*interpret + 0.017*particle + 0.017*detect + 0.017*vehicle + 0.016*perspective + 0.016*facial + 0.015*level + 0.015*like + 0.014*tool + 0.013*image + 0.013*vector + 0.013*inform + 0.013*minimize + 0.013*field'),\n",
       " (9,\n",
       "  '0.026*improve + 0.024*facial + 0.022*swarm + 0.020*certain + 0.019*appropriate + 0.019*pattern + 0.019*scheduling + 0.019*perspective + 0.018*recognition + 0.017*complex + 0.017*regression + 0.017*task + 0.017*algorithm + 0.017*particularly + 0.017*perception + 0.016*object + 0.016*useful + 0.016*increasingly + 0.015*perform + 0.014*management'),\n",
       " (10,\n",
       "  '0.030*retail + 0.030*metaheuristic + 0.022*vehicle + 0.021*swarm + 0.019*improve + 0.018*design + 0.017*explore + 0.017*traditional + 0.017*tool + 0.017*relationship + 0.016*optima + 0.015*method + 0.015*platform + 0.014*predict + 0.014*logistic + 0.014*pattern + 0.014*industry + 0.013*difficult + 0.013*utilize + 0.013*management'),\n",
       " (11,\n",
       "  '0.039*increasingly + 0.033*anomaly + 0.023*discover + 0.021*recommendation + 0.020*avoid + 0.018*artificial + 0.018*customer + 0.015*visual + 0.015*like + 0.014*certain + 0.014*vision + 0.014*vehicle + 0.013*field + 0.013*data + 0.013*annealing + 0.012*translation + 0.012*design + 0.011*rule + 0.011*minimize + 0.011*appropriate'),\n",
       " (12,\n",
       "  '0.048*strategy + 0.033*business + 0.025*process + 0.023*datum + 0.022*appropriate + 0.022*annealing + 0.017*scheduling + 0.017*medical + 0.016*detect + 0.016*continue + 0.016*large + 0.016*sight + 0.015*navigation + 0.015*context + 0.015*imaging + 0.014*database + 0.014*personalized + 0.014*support + 0.014*rule + 0.014*industry'),\n",
       " (13,\n",
       "  '0.030*detect + 0.027*like + 0.021*complex + 0.019*segmentation + 0.019*approach + 0.019*learning + 0.019*avoid + 0.018*regression + 0.018*innovative + 0.017*learn + 0.017*program + 0.016*sight + 0.015*vector + 0.015*technique + 0.015*size + 0.014*large + 0.014*make + 0.014*insight + 0.013*fraud + 0.013*mimic'),\n",
       " (14,\n",
       "  '0.034*enable + 0.031*regression + 0.023*marketing + 0.023*cluster + 0.022*search + 0.022*management + 0.021*datum + 0.019*certain + 0.018*valuable + 0.018*engineering + 0.018*making + 0.018*improve + 0.017*customer + 0.016*discover + 0.016*avoid + 0.016*behavior + 0.015*particularly + 0.015*system + 0.014*traditional + 0.014*relationship'),\n",
       " (15,\n",
       "  '0.028*task + 0.024*refer + 0.022*utilize + 0.022*recommendation + 0.021*behavior + 0.020*datum + 0.019*algorithm + 0.019*world + 0.017*efficiently + 0.017*cluster + 0.016*search + 0.016*deep + 0.015*traditional + 0.014*perform + 0.014*regression + 0.013*successful + 0.013*difficult + 0.013*avoid + 0.012*recognition + 0.012*facial'),\n",
       " (16,\n",
       "  '0.028*enable + 0.024*customer + 0.023*discover + 0.021*search + 0.019*industry + 0.019*capability + 0.018*adept + 0.018*learn + 0.016*computer + 0.016*experience + 0.016*model + 0.015*advance + 0.015*insight + 0.015*continue + 0.014*objective + 0.014*navigation + 0.014*program + 0.013*rule + 0.013*facial + 0.013*clustering'),\n",
       " (17,\n",
       "  '0.025*detection + 0.024*cluster + 0.021*language + 0.020*complex + 0.019*management + 0.019*high + 0.018*classification + 0.018*neural + 0.017*system + 0.017*space + 0.016*search + 0.016*rule + 0.016*tool + 0.016*local + 0.015*finance + 0.015*solution + 0.014*detect + 0.014*push + 0.014*vision + 0.014*interpret'),\n",
       " (18,\n",
       "  '0.031*efficiently + 0.026*solution + 0.025*simulate + 0.025*particle + 0.024*vision + 0.024*behavior + 0.024*support + 0.024*ability + 0.018*convolutional + 0.016*machine + 0.016*innovative + 0.016*dataset + 0.016*perform + 0.015*annealing + 0.014*autonomous + 0.014*industry + 0.013*continue + 0.013*task + 0.013*difficult + 0.013*vector'),\n",
       " (19,\n",
       "  '0.025*experience + 0.023*unnoticed + 0.020*autonomous + 0.020*approximate + 0.019*time + 0.019*allow + 0.018*vehicle + 0.017*design + 0.016*simulate + 0.016*optima + 0.016*tool + 0.015*insight + 0.014*like + 0.014*adept + 0.014*translation + 0.014*objective + 0.013*classification + 0.013*explore + 0.013*local + 0.013*perform')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import HdpModel\n",
    "\n",
    "hdpmodel = HdpModel(corpus=corpus, id2word=dictionary)\n",
    "hdpmodel.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Topic 1: Computer Vision and Machine Learning Systems\n",
    "Topic 2: Machine Learning and Algorithms\n",
    "Topic 3: Natural Language Processing and Text Mining\n",
    "Topic 4: Data Science and Big Data Analytics\n",
    "Topic 5: Healthcare and Predictive Analytics\n",
    "Topic 6: Social Media and Sentiment Analysis\n",
    "Topic 7: Artificial Intelligence and Robotics\n",
    "Topic 8: Financial Analysis and Risk Management\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
